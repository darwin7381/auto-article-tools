/**
 * Agent å·¥å…·å‡½æ•¸é›†åˆ
 * æä¾›èˆ‡AI Agentç›¸é—œçš„å…¬å…±å·¥å…·å’Œå¹«åŠ©å‡½æ•¸
 */

import { getJsonFromR2 } from '../../services/storage/r2Service';

// å®šç¾© Agent é…ç½®é¡å‹
export interface AgentConfig {
  provider: string;
  model: string;
  temperature: number;
  maxTokens: number;
  topP?: number;
  presencePenalty?: number;
  frequencyPenalty?: number;
  systemPrompt: string;
  userPrompt: string;
}

// å®šç¾©æ”¯æ´çš„æä¾›å•†
export type AIProvider = 'openai' | 'google';

// Gemini å°ˆç”¨é…ç½®ä»‹é¢
export interface GeminiMessage {
  role: 'user' | 'model';
  parts: Array<{ text: string }>;
}

export interface GeminiRequest {
  systemInstruction?: {
    parts: Array<{ text: string }>;
  };
  contents: GeminiMessage[];
  generationConfig: {
    temperature: number;
    maxOutputTokens: number;
    topP?: number;
  };
}

export interface GeminiResponse {
  candidates: Array<{
    content: {
      parts: Array<{ text: string }>;
      role: string;
    };
    finishReason: string;
  }>;
  usageMetadata: {
    promptTokenCount: number;
    candidatesTokenCount?: number;
    totalTokenCount: number;
  };
}

/**
 * æ ¼å¼åŒ–ç³»çµ±æç¤ºè©
 * @param basePrompt åŸºç¤æç¤ºå…§å®¹
 * @param options å¯é¸é…ç½®
 * @returns æ ¼å¼åŒ–å¾Œçš„ç³»çµ±æç¤ºè©
 */
export function formatSystemPrompt(basePrompt: string, options?: {
  includeInstructions?: string[];
}): string {
  let prompt = basePrompt;
  
  // æ·»åŠ é¡å¤–æŒ‡ç¤º
  if (options?.includeInstructions?.length) {
    prompt += '\n\né¡å¤–æŒ‡ç¤º:\n';
    options.includeInstructions.forEach((instruction, index) => {
      prompt += `${index + 1}. ${instruction}\n`;
    });
  }
  
  return prompt;
}

/**
 * å‰µå»ºåŸºæœ¬çš„ChatGPT APIé…ç½®
 * @param model æ¨¡å‹åç¨±
 * @param options æ¨¡å‹é¸é …
 * @returns API é…ç½®å°è±¡
 */
export function createChatConfig(model: string = "gpt-4o", options?: {
  temperature?: number;
  max_tokens?: number;
  top_p?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
  seed?: number;
}) {
  return {
    model,
    temperature: options?.temperature,
    max_tokens: options?.max_tokens,
    top_p: options?.top_p,
    frequency_penalty: options?.frequency_penalty,
    presence_penalty: options?.presence_penalty,
    seed: options?.seed,
  };
}

/**
 * åˆ¤æ–·æä¾›å•†é¡å‹
 * @param provider æä¾›å•†åç¨±
 * @returns æä¾›å•†é¡å‹
 */
export function getProviderType(provider: string): AIProvider {
  switch (provider.toLowerCase()) {
    case 'google':
    case 'gemini':
      return 'google';
    case 'openai':
    default:
      return 'openai';
  }
}

/**
 * æª¢æŸ¥æ˜¯å¦ç‚º Gemini æ¨¡å‹
 * @param model æ¨¡å‹åç¨±
 * @returns æ˜¯å¦ç‚º Gemini æ¨¡å‹
 */
export function isGeminiModel(model: string): boolean {
  const geminiModels = [
    'gemini-2.5-pro', 'gemini-2.5-flash', 
    'gemini-2.0-flash', 'gemini-2.0-flash-exp',
    'gemini-1.5-pro', 'gemini-1.5-flash'
  ];
  return geminiModels.some(geminiModel => model.startsWith(geminiModel));
}

/**
 * æª¢æŸ¥æ¨¡å‹æ˜¯å¦ç‚ºæ¨ç†æ¨¡å‹ï¼ˆéœ€è¦ä½¿ç”¨ max_completion_tokens ä¸”ä¸æ”¯æ´æ¡æ¨£åƒæ•¸ï¼‰
 * @param model æ¨¡å‹åç¨±
 * @returns æ˜¯å¦ç‚ºæ¨ç†æ¨¡å‹
 */
export function isReasoningModel(model: string): boolean {
  const openaiReasoningModels = [
    'o1', 'o1-preview', 'o1-mini', 'o1-pro',
    'o3', 'o3-mini', 'o3-pro', 
    'o4-mini', 'o4-mini-high'
  ];
  
  const geminiReasoningModels = [
    'gemini-2.5-pro' // Gemini Pro æ¨¡å‹æœ‰æ¨ç†èƒ½åŠ›
  ];
  
  return openaiReasoningModels.some(reasoningModel => model.startsWith(reasoningModel)) ||
         geminiReasoningModels.some(reasoningModel => model.startsWith(reasoningModel));
}

/**
 * èª¿ç”¨ Gemini API
 * @param agentConfig Agenté…ç½®
 * @param systemPrompt ç³»çµ±æç¤ºè©
 * @param userPrompt ç”¨æˆ¶æç¤ºè©
 * @returns AIå›æ‡‰å…§å®¹
 */
export async function callGeminiAPI(
  agentConfig: AgentConfig, 
  systemPrompt: string, 
  userPrompt: string
): Promise<string> {
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) {
    throw new Error('GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­ç½®');
  }

  // ä½¿ç”¨æ­£ç¢ºçš„ Gemini API æ ¼å¼ - åˆ†é›¢ systemInstruction å’Œ contents
  const request: GeminiRequest = {
    systemInstruction: {
      parts: [{ text: systemPrompt }]
    },
    contents: [{
      role: 'user',
      parts: [{ text: userPrompt }]
    }],
    generationConfig: {
      temperature: agentConfig.temperature,
      maxOutputTokens: agentConfig.maxTokens,
      topP: agentConfig.topP || 0.95
    }
  };

  const url = `https://generativelanguage.googleapis.com/v1beta/models/${agentConfig.model}:generateContent?key=${apiKey}`;
  
  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(request)
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Gemini API èª¿ç”¨å¤±æ•—: ${response.status} - ${errorText}`);
  }

  const data: GeminiResponse = await response.json();
  
  if (!data.candidates || data.candidates.length === 0) {
    throw new Error('Gemini API å›æ‡‰ç‚ºç©º');
  }

  const content = data.candidates[0]?.content?.parts[0]?.text;
  if (!content) {
    throw new Error('Gemini API å›æ‡‰å…§å®¹ç‚ºç©º');
  }

  return content;
}

/**
 * å‰µå»ºé©é…ä¸åŒæ¨¡å‹çš„APIé…ç½®ï¼ˆåƒ…ç”¨æ–¼ OpenAIï¼‰
 * @param agentConfig Agenté…ç½®
 * @returns API é…ç½®å°è±¡
 */
export function createModelAdaptedConfig(agentConfig: AgentConfig) {
  // æ ¹æ“šæ¨¡å‹é¡å‹ä½¿ç”¨ä¸åŒçš„åƒæ•¸é…ç½®
  if (isReasoningModel(agentConfig.model)) {
    // æ¨ç†æ¨¡å‹ï¼ˆo1, o3, etc.ï¼‰ï¼šåªæ”¯æ´åŸºæœ¬åƒæ•¸
    return {
      model: agentConfig.model,
      max_completion_tokens: agentConfig.maxTokens
      // æ³¨æ„ï¼šæ¨ç†æ¨¡å‹ä¸æ”¯æ´ temperature, top_p, presence_penalty, frequency_penalty
    };
  } else {
    // æ¨™æº–æ¨¡å‹ï¼šæ”¯æ´æ‰€æœ‰åƒæ•¸
    return {
      model: agentConfig.model,
      temperature: agentConfig.temperature,
      max_tokens: agentConfig.maxTokens,
      top_p: agentConfig.topP || 0.95,
      presence_penalty: agentConfig.presencePenalty || 0,
      frequency_penalty: agentConfig.frequencyPenalty || 0,
    };
  }
}

/**
 * è¨­ç½®JSONè¼¸å‡ºæ ¼å¼
 * @returns JSONæ ¼å¼é…ç½®
 */
export function withJsonOutput(schema?: object) {
  if (schema) {
    return {
      response_format: {
        type: "json_schema",
        schema
      }
    };
  }
  
  return {
    response_format: { type: "json_object" }
  };
}

/**
 * è‡ªå‹•é‡è©¦æ©Ÿåˆ¶ - å°AIè™•ç†æ“ä½œé€²è¡Œè‡ªå‹•é‡è©¦
 * @param operation è¦é‡è©¦çš„æ“ä½œå‡½æ•¸
 * @param options é‡è©¦é¸é …
 * @returns æ“ä½œçµæœ
 */
export async function withRetry<T>(
  operation: () => Promise<T>, 
  options: {
    maxRetries?: number;
    retryDelay?: number;
    onRetry?: (error: Error, retryCount: number) => void;
    retryCondition?: (error: unknown) => boolean;
  } = {}
): Promise<T> {
  const maxRetries = options.maxRetries ?? 3;
  const retryDelay = options.retryDelay ?? 1000;
  const onRetry = options.onRetry ?? ((error, count) => console.warn(`é‡è©¦ #${count}ï¼ŒéŒ¯èª¤:`, error.message));
  const retryCondition = options.retryCondition ?? (() => true);
  
  let lastError: unknown;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      lastError = error;
      
      // åˆ¤æ–·æ˜¯å¦ç¬¦åˆé‡è©¦æ¢ä»¶
      if (attempt < maxRetries && retryCondition(error)) {
        // é€šçŸ¥é‡è©¦å›èª¿
        if (error instanceof Error) {
          onRetry(error, attempt + 1);
        } else {
          onRetry(new Error(String(error)), attempt + 1);
        }
        
        // ç­‰å¾…å¾Œé‡è©¦
        await new Promise(resolve => setTimeout(resolve, retryDelay * (attempt + 1)));
      } else {
        break;
      }
    }
  }
  
  // æ‰€æœ‰é‡è©¦å¤±æ•—å¾Œæ‹‹å‡ºæœ€å¾Œçš„éŒ¯èª¤
  if (lastError instanceof Error) {
    throw lastError;
  }
  throw new Error(String(lastError));
}

/**
 * ç•°å¸¸å›é€€æ©Ÿåˆ¶ - åœ¨AIè™•ç†å¤±æ•—æ™‚æä¾›å®‰å…¨çš„å›é€€é¸é …
 * @param fallbackValue å›é€€å€¼
 * @param operation è¦å˜—è©¦çš„æ“ä½œ
 * @returns æ“ä½œçµæœæˆ–å›é€€å€¼
 */
export async function withFallback<T>(fallbackValue: T, operation: () => Promise<T>): Promise<T> {
  try {
    return await operation();
  } catch (error) {
    console.error('æ“ä½œå¤±æ•—ï¼Œä½¿ç”¨å›é€€å€¼:', error);
    return fallbackValue;
  }
}

/**
 * æ¸¬é‡AIæ“ä½œæ€§èƒ½
 * @param operation è¦æ¸¬é‡çš„æ“ä½œ
 * @returns çµæœå’Œæ€§èƒ½æ•¸æ“š
 */
export async function measurePerformance<T>(operation: () => Promise<T>): Promise<{
  result: T;
  metrics: {
    durationMs: number;
    timestamp: string;
  }
}> {
  const startTime = Date.now();
  
  try {
    const result = await operation();
    const endTime = Date.now();
    
    return {
      result,
      metrics: {
        durationMs: endTime - startTime,
        timestamp: new Date().toISOString()
      }
    };
  } catch (error) {
    const endTime = Date.now();
    console.error(`æ“ä½œå¤±æ•—ï¼Œè€—æ™‚: ${endTime - startTime}ms`);
    throw error;
  }
} 

/**
 * ç²å– Agent é…ç½®
 * @param agentName Agent åç¨±
 * @returns Agent é…ç½®
 */
export async function getAgentConfig(agentName: string): Promise<AgentConfig> {
  try {
    // å¾ R2 ç²å– Agent é…ç½®
    const config = await getJsonFromR2(`config/agents/${agentName}.json`);
    console.log(`âœ… æˆåŠŸè¼‰å…¥ ${agentName} é…ç½®`);
    return config as AgentConfig;
  } catch (error) {
    console.warn(`âš ï¸  ç„¡æ³•è¼‰å…¥ ${agentName} é…ç½®ï¼Œä½¿ç”¨é è¨­å€¼:`, error);
    
    // å¦‚æœç„¡æ³•ç²å–é…ç½®ï¼Œè¿”å›é è¨­é…ç½®
    const defaultConfigs: Record<string, AgentConfig> = {
      contentAgent: {
        provider: 'openai',
        model: 'gpt-4o',
        temperature: 0.3,
        maxTokens: 16000,
        systemPrompt: 'ä½ æ˜¯ä¸€å€‹ 30 å¹´ç¶“é©—çš„å½­åšç¤¾è³‡æ·±ç·¨è¼¯ï¼Œæ“…é•·ä»»ä½•å½¢å¼çš„æ­£è¦å°ˆæ¥­æ–°èç¨¿è™•ç†ã€‚',
        userPrompt: 'è«‹è™•ç†ä»¥ä¸‹ä¾†æºå…§å®¹ï¼š\n\n${markdownContent}'
      },
      prWriterAgent: {
        provider: 'openai',
        model: 'gpt-4o',
        temperature: 0.4,
        maxTokens: 16000,
        systemPrompt: 'ä½ æ˜¯ä¸€ä½æ“æœ‰15å¹´ç¶“é©—çš„PRæ–°èç¨¿å°ˆå®¶ï¼Œå°ˆé–€å°‡æ™®é€šå…§å®¹è½‰æ›ç‚ºå°ˆæ¥­çš„æ–°èç¨¿ã€‚',
        userPrompt: 'è«‹è™•ç†ä»¥ä¸‹ä¾†æºå…§å®¹ï¼š\n\n${markdownContent}'
      },
      copyEditorAgent: {
        provider: 'openai',
        model: 'gpt-4o',
        temperature: 0.3,
        maxTokens: 16000,
        systemPrompt: 'ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å…§å®¹åˆ†æå¸«å’ŒWordPressåƒæ•¸ç”Ÿæˆå°ˆå®¶ï¼Œè² è²¬åˆ†æç¶²ç«™æ–‡ç« ä¸¦ç”Ÿæˆé©åˆç™¼å¸ƒçš„åƒæ•¸å’Œå…§å®¹ã€‚',
        userPrompt: 'è«‹åˆ†æä»¥ä¸‹å…§å®¹ä¸¦ç”ŸæˆWordPressç™¼å¸ƒåƒæ•¸ï¼š\n\n${content}'
      }
    };
    
    return defaultConfigs[agentName] || {
      provider: 'openai',
      model: 'gpt-4o',
      temperature: 0.3,
      maxTokens: 16000,
      systemPrompt: 'ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„AIåŠ©æ‰‹ã€‚',
      userPrompt: 'è«‹è™•ç†ä»¥ä¸‹å…§å®¹ï¼š\n\n${content}'
    };
  }
}

/**
 * é€šç”¨ AI API èª¿ç”¨å‡½æ•¸
 * @param agentConfig Agenté…ç½®
 * @param systemPrompt ç³»çµ±æç¤ºè©
 * @param userPrompt ç”¨æˆ¶æç¤ºè©
 * @returns AIå›æ‡‰å…§å®¹
 */
export async function callAIAPI(
  agentConfig: AgentConfig, 
  systemPrompt: string, 
  userPrompt: string
): Promise<string> {
  const providerType = getProviderType(agentConfig.provider);
  
  switch (providerType) {
    case 'google':
      return await callGeminiAPI(agentConfig, systemPrompt, userPrompt);
      
    case 'openai':
    default:
      // é€™è£¡éœ€è¦å°å…¥ OpenAI å®¢æˆ¶ç«¯ï¼Œä½†ç‚ºäº†é¿å…å¾ªç’°ä¾è³´ï¼Œ
      // æˆ‘å€‘è®“èª¿ç”¨è€…è™•ç† OpenAI çš„æƒ…æ³
      throw new Error('OpenAI API èª¿ç”¨éœ€è¦åœ¨ Agent ä¸­è™•ç†');
  }
}

/**
 * è¨˜éŒ„æ¨¡å‹ä½¿ç”¨ä¿¡æ¯
 * @param agentName Agent åç¨±
 * @param config Agent é…ç½®
 * @param action åŸ·è¡Œçš„å‹•ä½œ
 */
export function logModelUsage(agentName: string, config: AgentConfig, action: string) {
  console.log(`ğŸ¤– [${agentName}] ${action}`);
  console.log(`ğŸ“¡ æä¾›å•†: ${config.provider || 'openai'}`);
  console.log(`ğŸ§  æ¨¡å‹: ${config.model || 'gpt-4o'}`);
  console.log(`ğŸŒ¡ï¸  æº«åº¦: ${config.temperature || 0.3}`);
  console.log(`ğŸ“ æœ€å¤§Token: ${config.maxTokens || 16000}`);
  
  const otherParams: Record<string, number | string> = {};
  
  // æ ¹æ“šæä¾›å•†é¡å‹é¡¯ç¤ºä¸åŒçš„åƒæ•¸
  const providerType = getProviderType(config.provider);
  if (providerType === 'google') {
    if (config.topP !== undefined) otherParams.topP = config.topP;
    // Gemini ä¸æ”¯æ´ presence_penalty å’Œ frequency_penalty
  } else {
    // OpenAI åƒæ•¸
    if (config.topP !== undefined) otherParams.top_p = config.topP;
    if (config.presencePenalty !== undefined) otherParams.presence_penalty = config.presencePenalty;
    if (config.frequencyPenalty !== undefined) otherParams.frequency_penalty = config.frequencyPenalty;
  }
  
  if (Object.keys(otherParams).length > 0) {
    console.log(`âš™ï¸  å…¶ä»–åƒæ•¸: ${JSON.stringify(otherParams)}`);
  }
}

/**
 * æ›¿æ›ç”¨æˆ¶ Prompt æ¨¡æ¿ä¸­çš„è®Šæ•¸
 * @param template æ¨¡æ¿å­—ç¬¦ä¸²
 * @param variables è®Šæ•¸å°è±¡
 * @returns æ›¿æ›å¾Œçš„å­—ç¬¦ä¸²
 */
export function replacePromptVariables(template: string, variables: Record<string, string>): string {
  // æª¢æŸ¥ template æ˜¯å¦ç‚ºæœ‰æ•ˆå­—ç¬¦ä¸²
  if (!template || typeof template !== 'string') {
    console.error('âŒ ç„¡æ•ˆçš„ template:', template);
    throw new Error('Prompt æ¨¡æ¿ç„¡æ•ˆæˆ–ç¼ºå¤±');
  }
  
  let result = template;
  
  // æ›¿æ›æ‰€æœ‰ ${variableName} æ ¼å¼çš„è®Šæ•¸
  Object.entries(variables).forEach(([key, value]) => {
    if (value !== undefined && value !== null) {
      const regex = new RegExp(`\\$\\{${key}\\}`, 'g');
      result = result.replace(regex, value);
    }
  });
  
  return result;
} 